{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samir\\Documents\\Python Scripts\\kaggle-retail-rocket\\notebooks\n",
      "C:\\Users\\samir\\Documents\\Python Scripts\\kaggle-retail-rocket\\notebooks/../\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samir\\anaconda3\\envs\\retail-rocket\\lib\\site-packages\\lightfm\\_lightfm_fast.py:9: UserWarning: LightFM was compiled without OpenMP support. Only a single thread will be used.\n",
      "  warnings.warn('LightFM was compiled without OpenMP support. '\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import sys\n",
    "\n",
    "from pathlib import Path\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "\n",
    "from IPython.display import display\n",
    "import pandas_profiling\n",
    "from pandas_profiling import ProfileReport\n",
    "%matplotlib inline\n",
    "\n",
    "from lightfm import LightFM\n",
    "\n",
    "\n",
    "\n",
    "print(os.path.abspath(''))\n",
    "root_path = os.path.abspath('')+\"/../\"\n",
    "print(root_path)\n",
    "data_folder = root_path+\"/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### read users interaction\n",
    "events = pd.read_csv(data_folder+\"events.csv\", header= 0)\n",
    "events_reduced = events.drop_duplicates()\n",
    "events_reduced = events_reduced.drop_duplicates(['visitorid', 'itemid'], keep='last').copy()\n",
    "events_tupel = []\n",
    "events_final = events_reduced.sort_values(by='timestamp', ascending=True).copy()\n",
    "events_final.loc[events_final['event'] == 'view', 'rating'] = 2\n",
    "events_final.loc[events_final['event'] == 'addtocart', 'rating'] = 3\n",
    "events_final.loc[events_final['event'] == 'transaction', 'rating'] = 5\n",
    "\n",
    "for index, row in events_final.iterrows():\n",
    "    events_tupel.append((row['visitorid'], row['itemid'], row['rating']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myconverter(obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        elif isinstance(obj, datetime.datetime):\n",
    "            return obj.__str__()\n",
    "        \n",
    "\n",
    "with open(data_folder+'/events_rating_tupel_1.json', 'w') as fp:\n",
    "    json.dump(events_tupel, fp, default=myconverter, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### load categories and items\n",
    "category_json = data_folder+\"cleaned_category.json\"\n",
    "cleaned_category = None\n",
    "with open(category_json) as json_file:\n",
    "    cleaned_category = json.load(json_file)\n",
    "    \n",
    "len(cleaned_category) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_json = data_folder+\"cleaned_items_indent.json\"\n",
    "cleaned_items = None\n",
    "with open(items_json) as json_file:\n",
    "    cleaned_items = json.load(json_file)\n",
    "    \n",
    "len(cleaned_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_array = [] #cleaned_items.values()\n",
    "\n",
    "for item_id in cleaned_items:\n",
    "    item_obj = cleaned_items[item_id]\n",
    "    item = dict()\n",
    "    categoryid = \"_\"+str(item_obj['property_categoryid'])\n",
    "    #print(cleaned_category[categoryid])\n",
    "    #print(categoryid)\n",
    "    category = None \n",
    "    if categoryid in cleaned_category:\n",
    "        category = cleaned_category[categoryid]\n",
    "        #print(category)\n",
    "    #item = cleaned_items[item_id]\n",
    "    item['item_id'] = item_id\n",
    "    item['property_790'] = item_obj['property_790']\n",
    "    if category is not None:\n",
    "        paths = category['path'].split('/')\n",
    "        size = len(paths)\n",
    "        item['cat_1'] = \"_\"+paths[0] if size > 0 else None  \n",
    "        item['cat_2'] = \"_\"+paths[1] if size > 1 else None\n",
    "        item['cat_3'] = \"_\"+paths[2] if size > 2 else None\n",
    "        \n",
    "    items_array.append(item)\n",
    "    #break\n",
    "\n",
    "\n",
    "print(len(items_array))\n",
    "#print(items_array[0])\n",
    "items = pd.DataFrame(items_array)\n",
    "#items = items[items.columns.drop(list(items.filter(regex='_ts_')))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = pd.read_csv(data_folder+\"events.csv\", header= 0)\n",
    "events_reduced = events.drop_duplicates()\n",
    "events_reduced = events_reduced.drop_duplicates(['visitorid', 'event', 'itemid']).copy()\n",
    "events_final = events_reduced.sort_values(by='timestamp', ascending=True).copy()\n",
    "events_final.loc[events_final['event'] == 'view', 'rating'] = 2\n",
    "events_final.loc[events_final['event'] == 'addtocart', 'rating'] = 3\n",
    "events_final.loc[events_final['event'] == 'transaction', 'rating'] = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_tupel = []\n",
    "for index, row in events_final.iterrows():\n",
    "    events_tupel.append((row['visitorid'], row['itemid'], row['rating']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### buillding user-item matrix\n",
    "from lightfm.data import Dataset\n",
    "\n",
    "feature_keys = ['cat_1', 'cat_2', 'cat_3', 'property_790'];\n",
    "\n",
    "dataset = Dataset(user_identity_features=False, item_identity_features=True)\n",
    "dataset.fit(events_final['visitorid'].to_numpy(), events_final['itemid'].to_numpy(), item_features=feature_keys)\n",
    "\n",
    "dataset.interactions_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "start_index = int(0.2*len(events_tupel))\n",
    "end_index = int(0.25*len(events_tupel))\n",
    "events_tupel = events_tupel[start_index:end_index]\n",
    "\n",
    "total_events = len(events_tupel)\n",
    "\n",
    "train_amt = int(0.9*total_events)\n",
    "events_train = events_tupel[:train_amt]\n",
    "events_test = events_tupel[(train_amt+1):]\n",
    "\n",
    "print(len(events_train))\n",
    "print(len(events_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(interactions_train, weights_train) = dataset.build_interactions(events_train)\n",
    "(interactions_test, weights_test) = dataset.build_interactions(events_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### build features\n",
    "item_features_tupel = []\n",
    "items_missing = []\n",
    "(item_mapping, user_mapping, item_features_mapping, user_features_mapping) = dataset.mapping()\n",
    "for index, row in items.iterrows():\n",
    "    item = row['item_id']\n",
    "    row_features = []\n",
    "    for attr in feature_keys:\n",
    "        row_features.append(row[attr])\n",
    "        \n",
    "    if item not in item_mapping:\n",
    "        items_missing.append([item, row_features])\n",
    "    else:\n",
    "        item_features_tupel.append([item, row_features])\n",
    "        \n",
    "item_features = dataset.build_item_features(item_features_tupel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from lightfm import LightFM\n",
    "\n",
    "model_bpr = LightFM(loss='bpr')\n",
    "%time model_bpr.fit(interactions_train, item_features=item_features, epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_wrp = LightFM(loss='warp')\n",
    "%time model_wrp.fit(interactions_train, item_features=item_features, epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightfm.evaluation import auc_score\n",
    "\n",
    "# Compute and print the AUC score\n",
    "%time train_auc = auc_score(model_bpr, interactions_train, item_features=item_features).mean()\n",
    "print('Collaborative filtering train AUC: %s' % train_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Compute and print the AUC score\n",
    "%time train_auc = auc_score(model_wrp, interactions_train, item_features=item_features).mean()\n",
    "print('Collaborative filtering train AUC: %s' % train_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%time train_auc = auc_score(model_bpr, interactions_test, train_interactions=interactions_train, item_features=item_features).mean()\n",
    "print('Collaborative filtering train AUC: %s' % train_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%time train_auc = auc_score(model_wrp, interactions_test, train_interactions=interactions_train, item_features=item_features).mean()\n",
    "print('Collaborative filtering train AUC: %s' % train_auc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
